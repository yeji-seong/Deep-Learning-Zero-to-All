{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB09"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logistic regression for XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.8353147 [[ 2.1289144 ]\n",
      " [-0.06878974]]\n",
      "1000 0.6931792 [[0.02389885]\n",
      " [0.01948566]]\n",
      "2000 0.6931472 [[0.00042996]\n",
      " [0.0004216 ]]\n",
      "3000 0.6931471 [[8.340132e-06]\n",
      " [8.328124e-06]]\n",
      "4000 0.6931472 [[1.6236635e-07]\n",
      " [1.6227949e-07]]\n",
      "5000 0.6931472 [[8.7860414e-08]\n",
      " [8.7773557e-08]]\n",
      "6000 0.6931472 [[8.7860414e-08]\n",
      " [8.7773557e-08]]\n",
      "7000 0.6931472 [[8.7860414e-08]\n",
      " [8.7773557e-08]]\n",
      "8000 0.6931472 [[8.7860414e-08]\n",
      " [8.7773557e-08]]\n",
      "9000 0.6931472 [[8.7860414e-08]\n",
      " [8.7773557e-08]]\n",
      "10000 0.6931472 [[8.7860414e-08]\n",
      " [8.7773557e-08]]\n",
      "\n",
      "Hypothesis:  [[0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]] \n",
      "Correct:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]] \n",
      "Accuracy:  0.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nHypothesis:  [[ 0.5]\\n [ 0.5]\\n [ 0.5]\\n [ 0.5]]\\nCorrect:  [[ 0.]\\n [ 0.]\\n [ 0.]\\n [ 0.]]\\nAccuracy:  0.5\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.set_random_seed(777)  # for reproducibility\n",
    "\n",
    "x_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=np.float32)\n",
    "y_data = np.array([[0], [1], [1], [0]], dtype=np.float32)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 2])\n",
    "Y = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([2, 1]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "\n",
    "# Hypothesis using sigmoid: tf.div(1., 1. + tf.exp(tf.matmul(X, W)))\n",
    "hypothesis = tf.sigmoid(tf.matmul(X, W) + b)\n",
    "\n",
    "# cost/loss function\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "# Accuracy computation\n",
    "# True if hypothesis>0.5 else False\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "\n",
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(10001):\n",
    "        _, cost_val, w_val = sess.run(\n",
    "                  [train, cost, W], feed_dict={X: x_data, Y: y_data}\n",
    "        )\n",
    "        if step % 1000 == 0:\n",
    "            print(step, cost_val, w_val)\n",
    "\n",
    "    # Accuracy report\n",
    "    h, c, a = sess.run(\n",
    "              [hypothesis, predicted, accuracy], feed_dict={X: x_data, Y: y_data}\n",
    "    )\n",
    "    print(\"\\nHypothesis: \", h, \"\\nCorrect: \", c, \"\\nAccuracy: \", a)\n",
    "\n",
    "'''\n",
    "Accuracy:  0.5\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logistic regression으로는 XOR 문제를 풀 수 없다. <br>\n",
    "단순한 데이터 셋으로 10000번 iteration을 돌려도 Accuracy는 0.5 밖에 안됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN for XOR\n",
    "### (1) normal NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.065737\n",
      "1000 0.69102114\n",
      "2000 0.6584269\n",
      "3000 0.55755436\n",
      "4000 0.42398483\n",
      "5000 0.12435085\n",
      "6000 0.05884724\n",
      "7000 0.03762524\n",
      "8000 0.027431522\n",
      "9000 0.021501211\n",
      "10000 0.017641194\n",
      "\n",
      "Hypothesis:\n",
      "[[0.02054024]\n",
      " [0.9833984 ]\n",
      " [0.98498195]\n",
      " [0.01776522]] \n",
      "Predicted:\n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]] \n",
      "Accuracy:\n",
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' \\nAccuracy:\\n1.0\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.set_random_seed(777)  # for reproducibility\n",
    "\n",
    "x_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=np.float32)\n",
    "y_data = np.array([[0], [1], [1], [0]], dtype=np.float32)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 2])\n",
    "Y = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([2, 2]), name='weight1')\n",
    "b1 = tf.Variable(tf.random_normal([2]), name='bias1')\n",
    "layer1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([2, 1]), name='weight2')\n",
    "b2 = tf.Variable(tf.random_normal([1]), name='bias2')\n",
    "hypothesis = tf.sigmoid(tf.matmul(layer1, W2) + b2)\n",
    "\n",
    "# cost/loss function\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "# Accuracy computation\n",
    "# True if hypothesis>0.5 else False\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "\n",
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(10001):\n",
    "        _, cost_val = sess.run([train, cost], feed_dict={X: x_data, Y: y_data})\n",
    "        if step % 1000 == 0:\n",
    "            print(step, cost_val)\n",
    "\n",
    "    # Accuracy report\n",
    "    h, p, a = sess.run(\n",
    "        [hypothesis, predicted, accuracy], feed_dict={X: x_data, Y: y_data}\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nHypothesis:\\n{h} \\nPredicted:\\n{p} \\nAccuracy:\\n{a}\")\n",
    "\n",
    "\n",
    "''' \n",
    "Accuracy:\n",
    "1.0\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wide NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "layer를 더 wide하게 조절 (# of layer1 output: 2 -> 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.74125326\n",
      "1000 0.2483334\n",
      "2000 0.07161234\n",
      "3000 0.03488757\n",
      "4000 0.021904558\n",
      "5000 0.015626885\n",
      "6000 0.012012463\n",
      "7000 0.0096921595\n",
      "8000 0.008088541\n",
      "9000 0.006919774\n",
      "10000 0.006033147\n",
      "\n",
      "Hypothesis:\n",
      "[[0.00389144]\n",
      " [0.9931226 ]\n",
      " [0.99446833]\n",
      " [0.00775194]] \n",
      "Predicted:\n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]] \n",
      "Accuracy:\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "tf.set_random_seed(777)  # for reproducibility\n",
    "\n",
    "x_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=np.float32)\n",
    "y_data = np.array([[0], [1], [1], [0]], dtype=np.float32)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 2])\n",
    "Y = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([2, 10]), name='weight1')\n",
    "b1 = tf.Variable(tf.random_normal([10]), name='bias1')\n",
    "layer1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([10, 1]), name='weight2')\n",
    "b2 = tf.Variable(tf.random_normal([1]), name='bias2')\n",
    "hypothesis = tf.sigmoid(tf.matmul(layer1, W2) + b2)\n",
    "\n",
    "# cost/loss function\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "# Accuracy computation\n",
    "# True if hypothesis>0.5 else False\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "\n",
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(10001):\n",
    "        _, cost_val = sess.run([train, cost], feed_dict={X: x_data, Y: y_data})\n",
    "        if step % 1000 == 0:\n",
    "            print(step, cost_val)\n",
    "\n",
    "    # Accuracy report\n",
    "    h, p, a = sess.run(\n",
    "        [hypothesis, predicted, accuracy], feed_dict={X: x_data, Y: y_data}\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nHypothesis:\\n{h} \\nPredicted:\\n{p} \\nAccuracy:\\n{a}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "layer를 좁게 설정했을때, (# of layer1 output = 2) <br>\n",
    "Hypothesis: <br>\n",
    "[[0.02054024] <br>\n",
    " [0.9833984 ] <br>\n",
    " [0.98498195] <br>\n",
    " [0.01776522]]<br><br>\n",
    " \n",
    "\n",
    "layer를 넓게 설정했을때, (# of layer1 output = 10) <br>\n",
    "Hypothesis: <br>\n",
    "[[0.00389144] <br>\n",
    " [0.9931226 ] <br>\n",
    " [0.99446833] <br>\n",
    " [0.00775194]] <br><br>\n",
    " \n",
    "=> Hypothesis의 값이 Y값에 더 가까워진다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wide and deep NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.4716208\n",
      "1000 0.56726146\n",
      "2000 0.035486676\n",
      "3000 0.011283865\n",
      "4000 0.006246767\n",
      "5000 0.0042090863\n",
      "6000 0.0031331265\n",
      "7000 0.0024763397\n",
      "8000 0.0020370986\n",
      "9000 0.0017241689\n",
      "10000 0.0014908058\n",
      "\n",
      "Hypothesis:  [[0.00117314]\n",
      " [0.9984368 ]\n",
      " [0.9985801 ]\n",
      " [0.00180161]] \n",
      "Correct:  [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]] \n",
      "Accuracy:  1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nHypothesis:  [[  7.80511764e-04]\\n [  9.99238133e-01]\\n [  9.98379230e-01]\\n [  1.55659032e-03]]\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.set_random_seed(777)  # for reproducibility\n",
    "\n",
    "x_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=np.float32)\n",
    "y_data = np.array([[0], [1], [1], [0]], dtype=np.float32)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 2])\n",
    "Y = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([2, 10]), name='weight1')\n",
    "b1 = tf.Variable(tf.random_normal([10]), name='bias1')\n",
    "layer1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([10, 10]), name='weight2')\n",
    "b2 = tf.Variable(tf.random_normal([10]), name='bias2')\n",
    "layer2 = tf.sigmoid(tf.matmul(layer1, W2) + b2)\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([10, 10]), name='weight3')\n",
    "b3 = tf.Variable(tf.random_normal([10]), name='bias3')\n",
    "layer3 = tf.sigmoid(tf.matmul(layer2, W3) + b3)\n",
    "\n",
    "W4 = tf.Variable(tf.random_normal([10, 1]), name='weight4')\n",
    "b4 = tf.Variable(tf.random_normal([1]), name='bias4')\n",
    "hypothesis = tf.sigmoid(tf.matmul(layer3, W4) + b4)\n",
    "\n",
    "# cost/loss function\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "# Accuracy computation\n",
    "# True if hypothesis>0.5 else False\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "\n",
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(10001):\n",
    "        _, cost_val = sess.run([train, cost], feed_dict={X: x_data, Y: y_data})\n",
    "        if step % 1000 == 0:\n",
    "            print(step, cost_val)\n",
    "\n",
    "    # Accuracy report\n",
    "    h, c, a = sess.run(\n",
    "        [hypothesis, predicted, accuracy], feed_dict={X: x_data, Y: y_data}\n",
    "    )\n",
    "    print(\"\\nHypothesis: \", h, \"\\nCorrect: \", c, \"\\nAccuracy: \", a)\n",
    "\n",
    "\n",
    "'''\n",
    "Hypothesis:  [[  7.80511764e-04]\n",
    " [  9.99238133e-01]\n",
    " [  9.98379230e-01]\n",
    " [  1.55659032e-03]]\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> 이전의 방법들보다 Hypothesis의 값이 Y값에 더 가까워진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "### wide and deep NN for MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Epoch: 0001, Cost: 1.835453442\n",
      "Epoch: 0002, Cost: 1.121580465\n",
      "Epoch: 0003, Cost: 0.887104101\n",
      "Epoch: 0004, Cost: 0.767083466\n",
      "Epoch: 0005, Cost: 0.688384049\n",
      "Epoch: 0006, Cost: 0.630046485\n",
      "Epoch: 0007, Cost: 0.583999566\n",
      "Epoch: 0008, Cost: 0.546748790\n",
      "Epoch: 0009, Cost: 0.515564668\n",
      "Epoch: 0010, Cost: 0.488779429\n",
      "Epoch: 0011, Cost: 0.466196669\n",
      "Epoch: 0012, Cost: 0.446091578\n",
      "Epoch: 0013, Cost: 0.428645722\n",
      "Epoch: 0014, Cost: 0.413385216\n",
      "Epoch: 0015, Cost: 0.399728788\n",
      "Learning finished\n",
      "Accuracy:  0.8767\n",
      "Label: [2]\n",
      "Prediction: [7]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time\n",
    "\n",
    "tf.reset_default_graph() \n",
    "\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "# Check out https://www.tensorflow.org/get_started/mnist/beginners for\n",
    "# more information about the mnist dataset\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "nb_classes = 10\n",
    "\n",
    "# MNIST data image of shape 28 * 28 = 784\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "# 0 - 9 digits recognition = 10 classes\n",
    "Y = tf.placeholder(tf.float32, [None, nb_classes])\n",
    "\n",
    "with tf.name_scope(\"Layer1\"):\n",
    "    W1 = tf.Variable(tf.random_normal([784, 50]))\n",
    "    b1 = tf.Variable(tf.random_normal([50]))\n",
    "    layer1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "    \n",
    "    tf.summary.histogram(\"W1\",W1)\n",
    "    tf.summary.histogram(\"b1\",b1)\n",
    "    tf.summary.histogram(\"Layer1\",layer1)\n",
    "\n",
    "with tf.name_scope(\"Layer2\"):\n",
    "    W2 = tf.Variable(tf.random_normal([50, 40]))\n",
    "    b2 = tf.Variable(tf.random_normal([40]))\n",
    "    layer2 = tf.sigmoid(tf.matmul(layer1, W2) + b2)\n",
    "    \n",
    "    tf.summary.histogram(\"W2\",W2)\n",
    "    tf.summary.histogram(\"b2\",b2)\n",
    "    tf.summary.histogram(\"Layer2\",layer2)\n",
    "    \n",
    "\n",
    "with tf.name_scope(\"Layer3\"):\n",
    "    W3 = tf.Variable(tf.random_normal([40, 20]))\n",
    "    b3 = tf.Variable(tf.random_normal([20]))\n",
    "    layer3 = tf.sigmoid(tf.matmul(layer2, W3) + b3)\n",
    "    \n",
    "    tf.summary.histogram(\"W3\",W3)\n",
    "    tf.summary.histogram(\"b3\",b3)\n",
    "    tf.summary.histogram(\"Layer3\",layer3)\n",
    "\n",
    "with tf.name_scope(\"Layer4\"):\n",
    "    W4 = tf.Variable(tf.random_normal([20, nb_classes]))\n",
    "    b4 = tf.Variable(tf.random_normal([nb_classes]))\n",
    "    hypothesis = tf.nn.softmax(tf.matmul(layer3, W4) + b4)\n",
    "\n",
    "    tf.summary.histogram(\"W4\",W4)\n",
    "    tf.summary.histogram(\"b4\",b4)\n",
    "    tf.summary.histogram(\"Hypothesis\",hypothesis)\n",
    "    \n",
    "\n",
    "with tf.name_scope(\"Cost\"):\n",
    "    cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), axis=1))\n",
    "    tf.summary.histogram(\"Cost\",cost)\n",
    "    \n",
    "with tf.name_scope(\"Train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "    \n",
    "# Test model\n",
    "is_correct = tf.equal(tf.arg_max(hypothesis, 1), tf.arg_max(Y, 1))\n",
    "# Calculate accuracy\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "tf.summary.scalar(\"accuracy\", accuracy)\n",
    "\n",
    "# parameters\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # tensorboard --logdir= (in cmd)\n",
    "    merged_summary = tf.summary.merge_all()\n",
    "    \n",
    "    writer = tf.summary.FileWriter(\"C:\\\\Users\\\\SAMSUNG\\\\tb\\\\mnist\")\n",
    "    writer.add_graph(sess.graph)  # Show the graph\n",
    "                         \n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0\n",
    "\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size) \n",
    "            _, summary, c = sess.run([optimizer, merged_summary, cost], feed_dict={X: batch_xs, Y: batch_ys})\n",
    "            writer.add_summary(summary, global_step=100)\n",
    "            avg_cost += c / total_batch\n",
    "                \n",
    "        print(\"Epoch: {:04d}, Cost: {:.9f}\".format(epoch + 1, avg_cost))\n",
    "\n",
    "    print(\"Learning finished\")    \n",
    "\n",
    "    # Test the model using test sets\n",
    "\n",
    "    print(\n",
    "        \"Accuracy: \",\n",
    "        accuracy.eval(\n",
    "            session=sess, feed_dict={X: mnist.test.images, Y: mnist.test.labels}\n",
    "        ),\n",
    "    )\n",
    "    acc1 = accuracy.eval(session=sess, feed_dict={X: mnist.test.images, Y: mnist.test.labels})\n",
    "                         \n",
    "    # Get one and predict\n",
    "    r = random.randint(0, mnist.test.num_examples - 1)\n",
    "    print(\"Label:\", sess.run(tf.argmax(mnist.test.labels[r:r+1], 1)))\n",
    "    print(\"Prediction:\", sess.run(tf.argmax(hypothesis, 1),feed_dict={X: mnist.test.images[r:r + 1]}))\n",
    "\n",
    "    plt.imshow(mnist.test.images[r:r + 1].reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> logistic regression (Accuracy:0.8895) 랑 Accuracy에 큰 차이 없음(?) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7168676\n",
      "1000 0.02237371\n",
      "2000 0.006315451\n",
      "3000 0.0027729846\n",
      "4000 0.0014256197\n",
      "5000 0.00078985246\n",
      "6000 0.0004553499\n",
      "7000 0.00026845094\n",
      "8000 0.00016037926\n",
      "9000 9.653442e-05\n",
      "10000 5.836957e-05\n",
      "\n",
      "Hypothesis:\n",
      "[[6.1333179e-05]\n",
      " [9.9993688e-01]\n",
      " [9.9995077e-01]\n",
      " [5.9783459e-05]] \n",
      "Predicted:\n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]] \n",
      "Accuracy:\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.reset_default_graph() \n",
    "\n",
    "tf.set_random_seed(777)  # for reproducibility\n",
    "\n",
    "x_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=np.float32)\n",
    "y_data = np.array([[0], [1], [1], [0]], dtype=np.float32)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 2], name=\"x\")\n",
    "Y = tf.placeholder(tf.float32, [None, 1], name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"Layer1\"):\n",
    "    W1 = tf.Variable(tf.random_normal([2, 2]), name=\"weight_1\")\n",
    "    b1 = tf.Variable(tf.random_normal([2]), name=\"bias_1\")\n",
    "    layer1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "\n",
    "    tf.summary.histogram(\"W1\", W1)\n",
    "    tf.summary.histogram(\"b1\", b1)\n",
    "    tf.summary.histogram(\"Layer1\", layer1)\n",
    "\n",
    "\n",
    "with tf.name_scope(\"Layer2\"):\n",
    "    W2 = tf.Variable(tf.random_normal([2, 1]), name=\"weight_2\")\n",
    "    b2 = tf.Variable(tf.random_normal([1]), name=\"bias_2\")\n",
    "    hypothesis = tf.sigmoid(tf.matmul(layer1, W2) + b2)\n",
    "\n",
    "    tf.summary.histogram(\"W2\", W2)\n",
    "    tf.summary.histogram(\"b2\", b2)\n",
    "    tf.summary.histogram(\"Hypothesis\", hypothesis)\n",
    "\n",
    "# cost/loss function\n",
    "with tf.name_scope(\"Cost\"):\n",
    "    cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))\n",
    "    tf.summary.scalar(\"Cost\", cost)\n",
    "\n",
    "with tf.name_scope(\"Train\"):\n",
    "    train = tf.train.AdamOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "# Accuracy computation\n",
    "# True if hypothesis>0.5 else False\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "tf.summary.scalar(\"accuracy\", accuracy)\n",
    "\n",
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    # tensorboard --logdir=./logs/xor_logs\n",
    "    merged_summary = tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter(\"C:\\\\Users\\\\SAMSUNG\\\\tb\")\n",
    "    writer.add_graph(sess.graph)  # Show the graph\n",
    "\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(10001):\n",
    "        _, summary, cost_val = sess.run(\n",
    "            [train, merged_summary, cost], feed_dict={X: x_data, Y: y_data}\n",
    "        )\n",
    "        writer.add_summary(summary, global_step=step)\n",
    "\n",
    "        if step % 1000 == 0:\n",
    "            print(step, cost_val)\n",
    "\n",
    "    # Accuracy report\n",
    "    h, p, a = sess.run(\n",
    "        [hypothesis, predicted, accuracy], feed_dict={X: x_data, Y: y_data}\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nHypothesis:\\n{h} \\nPredicted:\\n{p} \\nAccuracy:\\n{a}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensorboard 실행 안됨\n",
    "=> 13장에서 다시"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
