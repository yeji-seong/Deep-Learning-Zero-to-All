{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning rate, Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.6437182 [[ 1.6164407   0.35159314 -0.54730886]\n",
      " [ 0.26799688 -0.86443686 -1.3842125 ]\n",
      " [-0.98051786 -0.1299563   0.5812885 ]]\n",
      "20 1.3151286 [[ 1.4203331   0.21971405 -0.21932222]\n",
      " [-0.02554411 -0.890712   -1.0643963 ]\n",
      " [-0.7123943  -0.06478579  0.24799442]]\n",
      "40 1.0697334 [[ 1.2603878   0.08516014  0.07517686]\n",
      " [-0.21238121 -0.882714   -0.885557  ]\n",
      " [-0.45425683 -0.03107127 -0.04385751]]\n",
      "60 0.9142951 [[ 1.1231289  -0.03152284  0.32911888]\n",
      " [-0.3427805  -0.8543336  -0.78353804]\n",
      " [-0.26155642 -0.01421113 -0.25341797]]\n",
      "80 0.818159 [[ 1.0020096  -0.12389229  0.5426078 ]\n",
      " [-0.42555276 -0.82282245 -0.7322769 ]\n",
      " [-0.12500836 -0.00535078 -0.3988263 ]]\n",
      "100 0.75567305 [[ 8.9168543e-01 -1.9420117e-01  7.2324085e-01]\n",
      " [-4.7397155e-01 -7.9582793e-01 -7.1085256e-01]\n",
      " [-2.9064763e-02  5.8136717e-04 -5.0070196e-01]]\n",
      "120 0.71176887 [[ 0.7890849  -0.24712224  0.8787624 ]\n",
      " [-0.5002476  -0.7745553  -0.70584893]\n",
      " [ 0.04034263  0.00537906 -0.5749068 ]]\n",
      "140 0.67865026 [[ 0.6925545  -0.2869321   1.0151026 ]\n",
      " [-0.51330405 -0.7579511  -0.7093967 ]\n",
      " [ 0.09328361  0.00936711 -0.6318359 ]]\n",
      "160 0.65228873 [[ 0.6010888  -0.31689614  1.1365325 ]\n",
      " [-0.5188874  -0.7447284  -0.7170359 ]\n",
      " [ 0.1362023   0.01252292 -0.67791045]]\n",
      "180 0.63047504 [[ 0.5139699  -0.33937946  1.2461348 ]\n",
      " [-0.52044725 -0.7339066  -0.72629786]\n",
      " [ 0.17300548  0.01483513 -0.7170257 ]]\n",
      "200 0.6118995 [[ 0.43063056 -0.3560849   1.3461797 ]\n",
      " [-0.5199696  -0.72482336 -0.7358585 ]\n",
      " [ 0.206005    0.01635139 -0.75154144]]\n",
      "Prediction:  [2 2 2]\n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x_data = [[1,2,1],[1,3,2],[1,3,4],[1,5,5],[1,7,5],[1,2,5],[1,6,6],[1,7,7]]\n",
    "y_data = [[0,0,1],[0,0,1],[0,0,1],[0,1,0],[0,1,0],[0,1,0],[1,0,0],[1,0,0]]\n",
    "\n",
    "x_test = [[2,1,1],[3,1,2],[3,3,4]]\n",
    "y_test = [[0,0,1],[0,0,1],[0,0,1]]\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, 3])\n",
    "Y = tf.placeholder(\"float\", [None, 3])\n",
    "W = tf.Variable(tf.random_normal([3,3]))\n",
    "b = tf.Variable(tf.random_normal([3]))\n",
    "\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X, W) +b)\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y*tf.log(hypothesis), axis=1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.1).minimize(cost)\n",
    "\n",
    "# Correct prediction Test model\n",
    "prediction = tf.arg_max(hypothesis, 1)\n",
    "is_correct = tf.equal(prediction, tf.arg_max(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    # Initialize Tensorflow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(201):\n",
    "        cost_val, W_val, _ = sess.run([cost, W, optimizer], feed_dict = {X:x_data, Y:y_data})\n",
    "        if step % 20 == 0:\n",
    "            print(step, cost_val, W_val)\n",
    "        \n",
    "    # predict\n",
    "    print(\"Prediction: \", sess.run(prediction, feed_dict = {X: x_test}))\n",
    "    # Calculate the accuracy\n",
    "    print(\"Accuracy: \", sess.run(accuracy, feed_dict = {X:x_test, Y: y_test}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning rate - (1) Big learning rate <br>\n",
    "\n",
    "cost 값이 inf로 발산 (overshooting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4.702512 [[-0.26601616 -1.9255261   0.45276666]\n",
      " [-2.5634222   1.3529696  -0.34482735]\n",
      " [-2.6238728   2.7689817   0.28742105]]\n",
      "20 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "40 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "60 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "80 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "100 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "120 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "140 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "160 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "180 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "200 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "Prediction:  [0 0 0]\n",
      "Accuracy:  0.0\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(\"float\", [None, 3])\n",
    "Y = tf.placeholder(\"float\", [None, 3])\n",
    "W = tf.Variable(tf.random_normal([3,3]))\n",
    "b = tf.Variable(tf.random_normal([3]))\n",
    "\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X, W) +b)\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y*tf.log(hypothesis), axis=1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 1.5).minimize(cost)\n",
    "\n",
    "# Correct prediction Test model\n",
    "prediction = tf.arg_max(hypothesis, 1)\n",
    "is_correct = tf.equal(prediction, tf.arg_max(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    # Initialize Tensorflow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(201):\n",
    "        cost_val, W_val, _ = sess.run([cost, W, optimizer], feed_dict = {X:x_data, Y:y_data})\n",
    "        if step % 20 == 0:\n",
    "            print(step, cost_val, W_val)\n",
    "        \n",
    "    # predict\n",
    "    print(\"Prediction: \", sess.run(prediction, feed_dict = {X: x_test}))\n",
    "    # Calculate the accuracy\n",
    "    print(\"Accuracy: \", sess.run(accuracy, feed_dict = {X:x_test, Y: y_test}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning rate - (2) Small learning rate <br>\n",
    "\n",
    "수렴 속도가 매우 느리거나, local minima에 빠질 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 6.006279 [[-0.10332307  0.4034278  -0.2573104 ]\n",
      " [ 0.7078875   1.1741198  -1.1441443 ]\n",
      " [-0.7138933   0.39611277 -0.80714494]]\n",
      "20 6.006279 [[-0.10332307  0.4034278  -0.2573104 ]\n",
      " [ 0.7078875   1.1741198  -1.1441443 ]\n",
      " [-0.7138933   0.39611277 -0.80714494]]\n",
      "40 6.006279 [[-0.10332307  0.4034278  -0.2573104 ]\n",
      " [ 0.7078875   1.1741198  -1.1441443 ]\n",
      " [-0.7138933   0.39611277 -0.80714494]]\n",
      "60 6.006279 [[-0.10332307  0.4034278  -0.2573104 ]\n",
      " [ 0.7078875   1.1741198  -1.1441443 ]\n",
      " [-0.7138933   0.39611277 -0.80714494]]\n",
      "80 6.006279 [[-0.10332307  0.4034278  -0.2573104 ]\n",
      " [ 0.7078875   1.1741198  -1.1441443 ]\n",
      " [-0.7138933   0.39611277 -0.80714494]]\n",
      "100 6.006279 [[-0.10332307  0.4034278  -0.2573104 ]\n",
      " [ 0.7078875   1.1741198  -1.1441443 ]\n",
      " [-0.7138933   0.39611277 -0.80714494]]\n",
      "120 6.006279 [[-0.10332307  0.4034278  -0.2573104 ]\n",
      " [ 0.7078875   1.1741198  -1.1441443 ]\n",
      " [-0.7138933   0.39611277 -0.80714494]]\n",
      "140 6.006279 [[-0.10332307  0.4034278  -0.2573104 ]\n",
      " [ 0.7078875   1.1741198  -1.1441443 ]\n",
      " [-0.7138933   0.39611277 -0.80714494]]\n",
      "160 6.006279 [[-0.10332307  0.4034278  -0.2573104 ]\n",
      " [ 0.7078875   1.1741198  -1.1441443 ]\n",
      " [-0.7138933   0.39611277 -0.80714494]]\n",
      "180 6.006279 [[-0.10332307  0.4034278  -0.2573104 ]\n",
      " [ 0.7078875   1.1741198  -1.1441443 ]\n",
      " [-0.7138933   0.39611277 -0.80714494]]\n",
      "200 6.006279 [[-0.10332307  0.4034278  -0.2573104 ]\n",
      " [ 0.7078875   1.1741198  -1.1441443 ]\n",
      " [-0.7138933   0.39611277 -0.80714494]]\n",
      "Prediction:  [1 1 1]\n",
      "Accuracy:  0.0\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(\"float\", [None, 3])\n",
    "Y = tf.placeholder(\"float\", [None, 3])\n",
    "W = tf.Variable(tf.random_normal([3,3]))\n",
    "b = tf.Variable(tf.random_normal([3]))\n",
    "\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X, W) +b)\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y*tf.log(hypothesis), axis=1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 1e-10).minimize(cost)\n",
    "\n",
    "# Correct prediction Test model\n",
    "prediction = tf.arg_max(hypothesis, 1)\n",
    "is_correct = tf.equal(prediction, tf.arg_max(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    # Initialize Tensorflow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(201):\n",
    "        cost_val, W_val, _ = sess.run([cost, W, optimizer], feed_dict = {X:x_data, Y:y_data})\n",
    "        if step % 20 == 0:\n",
    "            print(step, cost_val, W_val)\n",
    "        \n",
    "    # predict\n",
    "    print(\"Prediction: \", sess.run(prediction, feed_dict = {X: x_test}))\n",
    "    # Calculate the accuracy\n",
    "    print(\"Accuracy: \", sess.run(accuracy, feed_dict = {X:x_test, Y: y_test}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize - (1) Non-normalized inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### np.array() : array 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Cost:  2772009000000.0 \n",
      "Prediction:\n",
      " [[1174778. ]\n",
      " [2365657. ]\n",
      " [1860832.8]\n",
      " [1304231.1]\n",
      " [1537227.1]\n",
      " [1550171.6]\n",
      " [1420735.1]\n",
      " [1809061.8]]\n",
      "1 Cost:  3.045552e+27 \n",
      "Prediction:\n",
      " [[-3.8928199e+13]\n",
      " [-7.8366460e+13]\n",
      " [-6.1648061e+13]\n",
      " [-4.3214963e+13]\n",
      " [-5.0931144e+13]\n",
      " [-5.1359819e+13]\n",
      " [-4.7073055e+13]\n",
      " [-5.9933354e+13]]\n",
      "2 Cost:  inf \n",
      "Prediction:\n",
      " [[1.2903275e+21]\n",
      " [2.5975617e+21]\n",
      " [2.0434081e+21]\n",
      " [1.4324181e+21]\n",
      " [1.6881814e+21]\n",
      " [1.7023905e+21]\n",
      " [1.5602998e+21]\n",
      " [1.9865719e+21]]\n",
      "3 Cost:  inf \n",
      "Prediction:\n",
      " [[-4.2769647e+28]\n",
      " [-8.6099697e+28]\n",
      " [-6.7731519e+28]\n",
      " [-4.7479433e+28]\n",
      " [-5.5957049e+28]\n",
      " [-5.6428029e+28]\n",
      " [-5.1718243e+28]\n",
      " [-6.5847602e+28]]\n",
      "4 Cost:  inf \n",
      "Prediction:\n",
      " [[1.4176579e+36]\n",
      " [2.8538910e+36]\n",
      " [2.2450528e+36]\n",
      " [1.5737702e+36]\n",
      " [1.8547722e+36]\n",
      " [1.8703834e+36]\n",
      " [1.7142712e+36]\n",
      " [2.1826080e+36]]\n",
      "5 Cost:  inf \n",
      "Prediction:\n",
      " [[-inf]\n",
      " [-inf]\n",
      " [-inf]\n",
      " [-inf]\n",
      " [-inf]\n",
      " [-inf]\n",
      " [-inf]\n",
      " [-inf]]\n",
      "6 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "7 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "8 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "9 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "10 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "xy = np.array([[828.659973, 833.450012, 908100, 828.349976, 831.659973],\n",
    "              [823.02002, 828.070007, 1828100, 821.655029, 828.070007],\n",
    "              [819.929993, 824.400024, 1438100, 818.97998, 824.159973],\n",
    "              [816, 820.958984, 1008100, 815.48999, 819.23999],\n",
    "              [819.359985, 823, 1188100, 818.469971, 818.97998],\n",
    "              [819, 823, 1198100, 816, 820.450012],\n",
    "              [811.700012, 815.25, 1098100, 809.780029, 813.669983],\n",
    "              [809.51001, 816.659973, 1398100, 804.539978, 809.559998]])\n",
    "\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "\n",
    "# placeholders for a tensor that will be always fed.\n",
    "X = tf.placeholder(tf.float32, shape=[None, 4])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "W = tf.Variable(tf.random_normal([4, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(2001):\n",
    "    cost_val, hy_val, _ = sess.run(\n",
    "       [cost, hypothesis, train], feed_dict={X: x_data, Y: y_data})\n",
    "    if 0<=step<=10:\n",
    "        print(step, \"Cost: \", cost_val, \"\\nPrediction:\\n\", hy_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize - (2) Normalized inputs (min-max scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### from sklearn.preprocessing import MinMaxScaler <br>\n",
    "#### MinMaxScaler()  : min-max scale <br>\n",
    "#### fit_transform() :  fit과 transform을 한번에 수행\n",
    "(https://datascience.stackexchange.com/questions/12321/whats-the-difference-between-fit-and-fit-transform-in-scikit-learn-models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         1.         0.         1.         1.        ]\n",
      " [0.70548491 0.70439552 1.         0.71881783 0.83755792]\n",
      " [0.54412549 0.50274824 0.57608696 0.60646801 0.6606331 ]\n",
      " [0.33890353 0.31368023 0.10869565 0.45989134 0.43800918]\n",
      " [0.51436    0.4258239  0.30434783 0.58504805 0.42624401]\n",
      " [0.49556179 0.4258239  0.31521739 0.48131134 0.49276137]\n",
      " [0.11436064 0.         0.20652174 0.22007776 0.18597238]\n",
      " [0.         0.07747099 0.5326087  0.         0.        ]]\n",
      "0 Cost:  0.2038711 \n",
      "Prediction:\n",
      " [[0.22432426]\n",
      " [1.4709677 ]\n",
      " [0.79694486]\n",
      " [0.09787324]\n",
      " [0.3766752 ]\n",
      " [0.42906177]\n",
      " [0.08256976]\n",
      " [0.69036794]]\n",
      "500 Cost:  0.20338577 \n",
      "Prediction:\n",
      " [[0.2257585 ]\n",
      " [1.470688  ]\n",
      " [0.79694986]\n",
      " [0.09817822]\n",
      " [0.3769567 ]\n",
      " [0.42925748]\n",
      " [0.08234531]\n",
      " [0.6895757 ]]\n",
      "1000 Cost:  0.20290121 \n",
      "Prediction:\n",
      " [[0.22719273]\n",
      " [1.4704084 ]\n",
      " [0.79695475]\n",
      " [0.09848319]\n",
      " [0.3772382 ]\n",
      " [0.4294532 ]\n",
      " [0.08212084]\n",
      " [0.68878347]]\n",
      "1500 Cost:  0.20241834 \n",
      "Prediction:\n",
      " [[0.22861463]\n",
      " [1.4701194 ]\n",
      " [0.79695165]\n",
      " [0.09878196]\n",
      " [0.37751198]\n",
      " [0.42964128]\n",
      " [0.08189231]\n",
      " [0.6879883 ]]\n",
      "2000 Cost:  0.20193745 \n",
      "Prediction:\n",
      " [[0.23002452]\n",
      " [1.4698215 ]\n",
      " [0.7969413 ]\n",
      " [0.09907553]\n",
      " [0.37777874]\n",
      " [0.42982313]\n",
      " [0.08166116]\n",
      " [0.6871923 ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler \n",
    "\n",
    "xy = np.array([[828.659973, 833.450012, 908100, 828.349976, 831.659973],\n",
    "              [823.02002, 828.070007, 1828100, 821.655029, 828.070007],\n",
    "              [819.929993, 824.400024, 1438100, 818.97998, 824.159973],\n",
    "              [816, 820.958984, 1008100, 815.48999, 819.23999],\n",
    "              [819.359985, 823, 1188100, 818.469971, 818.97998],\n",
    "              [819, 823, 1198100, 816, 820.450012],\n",
    "              [811.700012, 815.25, 1098100, 809.780029, 813.669983],\n",
    "              [809.51001, 816.659973, 1398100, 804.539978, 809.559998]])\n",
    "xy = MinMaxScaler().fit_transform(xy)\n",
    "\n",
    "print(xy)\n",
    "\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "\n",
    "# placeholders for a tensor that will be always fed.\n",
    "X = tf.placeholder(tf.float32, shape=[None, 4])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "W = tf.Variable(tf.random_normal([4, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(2001):\n",
    "    cost_val, hy_val, _ = sess.run(\n",
    "       [cost, hypothesis, train], feed_dict={X: x_data, Y: y_data})\n",
    "    if step % 500 ==0 :\n",
    "        print(step, \"Cost: \", cost_val, \"\\nPrediction:\\n\", hy_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### from tensorflow.examples.tutorials.mnist import input_data\n",
    "#### input_data.read_data_sets() : mnist data sets 읽기 <br>\n",
    "\n",
    "#### mnist.train.next_batch() : 다음 batch를 가져옴 <br><br>\n",
    "\n",
    "#### accuracy.eval(session=sess, ) : sess.run(accuracy) <br><br>\n",
    "\n",
    "#### import matplotlib.pyplot as plt \n",
    "#### plt.imshow() : Display an image, i.e. data on a 2D regular raster. <br><br>\n",
    "\n",
    "#### import random\n",
    "#### random.randint() : random int 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Epoch: 0001, Cost: 2.527230883\n",
      "Epoch: 0002, Cost: 1.077644026\n",
      "Epoch: 0003, Cost: 0.868696794\n",
      "Epoch: 0004, Cost: 0.763737372\n",
      "Epoch: 0005, Cost: 0.697155176\n",
      "Epoch: 0006, Cost: 0.649520282\n",
      "Epoch: 0007, Cost: 0.613696377\n",
      "Epoch: 0008, Cost: 0.584700517\n",
      "Epoch: 0009, Cost: 0.560351812\n",
      "Epoch: 0010, Cost: 0.539902680\n",
      "Epoch: 0011, Cost: 0.522724563\n",
      "Epoch: 0012, Cost: 0.506899691\n",
      "Epoch: 0013, Cost: 0.493836051\n",
      "Epoch: 0014, Cost: 0.481988384\n",
      "Epoch: 0015, Cost: 0.470796883\n",
      "Learning finished\n",
      "Accuracy:  0.8895\n",
      "Label: [3]\n",
      "Prediction: [3]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "# Check out https://www.tensorflow.org/get_started/mnist/beginners for\n",
    "# more information about the mnist dataset\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "nb_classes = 10\n",
    "\n",
    "# MNIST data image of shape 28 * 28 = 784\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "# 0 - 9 digits recognition = 10 classes\n",
    "Y = tf.placeholder(tf.float32, [None, nb_classes])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([784, nb_classes]))\n",
    "b = tf.Variable(tf.random_normal([nb_classes]))\n",
    "\n",
    "# Hypothesis (using softmax)\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), axis=1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "# Test model\n",
    "is_correct = tf.equal(tf.arg_max(hypothesis, 1), tf.arg_max(Y, 1))\n",
    "# Calculate accuracy\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "# parameters\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0\n",
    "\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            _, c = sess.run([optimizer, cost], feed_dict={X: batch_xs, Y: batch_ys})\n",
    "            avg_cost += c / total_batch\n",
    "\n",
    "        print(\"Epoch: {:04d}, Cost: {:.9f}\".format(epoch + 1, avg_cost))\n",
    "\n",
    "    print(\"Learning finished\")\n",
    "    \n",
    "\n",
    "    # Test the model using test sets\n",
    "    print(\n",
    "        \"Accuracy: \",\n",
    "        accuracy.eval(\n",
    "            session=sess, feed_dict={X: mnist.test.images, Y: mnist.test.labels}\n",
    "        ),\n",
    "    )\n",
    "    \n",
    "    # Get one and predict\n",
    "    r = random.randint(0, mnist.test.num_examples - 1)\n",
    "    print(\"Label:\", sess.run(tf.argmax(mnist.test.labels[r:r+1], 1)))\n",
    "    print(\"Prediction:\", sess.run(tf.argmax(hypothesis, 1),feed_dict={X: mnist.test.images[r:r + 1]}))\n",
    "\n",
    "    plt.imshow(mnist.test.images[r:r + 1].reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
